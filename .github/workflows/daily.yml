name: TrainStats Daily Pipeline

on:
  schedule:
    - cron: "30 2 * * *"
  workflow_dispatch:
    inputs:
      start_date:
        description: "Start date YYYY-MM-DD"
        required: false
        type: string
      end_date:
        description: "End date YYYY-MM-DD"
        required: false
        type: string

permissions:
  contents: write

concurrency:
  group: pages
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run pipeline
        env:
          START_DATE: ${{ inputs.start_date }}
          END_DATE: ${{ inputs.end_date }}
        run: |
          set -euo pipefail

          if [ -n "${START_DATE:-}" ] && [ -z "${END_DATE:-}" ]; then
            END_DATE="$START_DATE"
          fi

          if [ -n "${START_DATE:-}" ]; then
            echo "Running backfill from $START_DATE to $END_DATE"
            python -m scripts.run_pipeline --start "$START_DATE" --end "$END_DATE"
          else
            echo "Running daily pipeline"
            python -m scripts.run_pipeline
          fi

      - name: Ensure gold and site artifacts are built
        run: |
          set -euo pipefail

          python -m scripts.build_gold
          python -m scripts.build_station_dim

          if python -m scripts.build_site; then
            echo "build_site ok"
          else
            echo "build_site missing or failed, creating minimal manifest in site/data"
            mkdir -p site/data
            python - <<'PY'
import os, json, glob, datetime
os.makedirs("site/data", exist_ok=True)
gold = sorted([os.path.basename(p) for p in glob.glob("data/gold/*.csv")])
man = {
  "built_at_utc": datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z",
  "gold_files": gold,
}
with open("site/data/manifest.json", "w", encoding="utf-8") as f:
  json.dump(man, f, ensure_ascii=False, indent=2)
print({"manifest_written": "site/data/manifest.json", "gold_files": len(gold)})
PY
          fi

          if [ ! -d data/gold ] || [ -z "$(ls -1 data/gold/*.csv 2>/dev/null | head -n 1)" ]; then
            echo "No gold CSV produced, failing"
            exit 1
          fi

      - name: Sanity check bronze rows
        env:
          START_DATE: ${{ inputs.start_date }}
          END_DATE: ${{ inputs.end_date }}
        run: |
          set -euo pipefail
          python - <<'PY'
import gzip, os
from datetime import date, timedelta

start = os.environ.get("START_DATE") or ""
end = os.environ.get("END_DATE") or ""

if not start:
  print({"sanity_check": "skipped", "reason": "no START_DATE provided"})
  raise SystemExit(0)

if not end:
  end = start

d0 = date.fromisoformat(start)
d1 = date.fromisoformat(end)
if d1 < d0:
  raise SystemExit("END_DATE must be >= START_DATE")

cur = d0
total_rows = 0

while cur <= d1:
  y = f"{cur.year:04d}"
  m = f"{cur.month:02d}"
  dd = f"{cur.day:02d}"
  p = f"data/bronze/{y}/{m}/{y}{m}{dd}.csv.gz"

  if not os.path.exists(p):
    print({"date": cur.isoformat(), "bronze": "missing", "path": p})
  else:
    with gzip.open(p, "rt", encoding="utf-8", errors="replace") as f:
      n = sum(1 for _ in f) - 1
    n = max(n, 0)
    total_rows += n
    print({"date": cur.isoformat(), "bronze_rows": n, "path": p})

  cur += timedelta(days=1)

print({"bronze_total_rows": total_rows})
PY

      - name: Update stations unknown list
        run: |
          python -m scripts.update_stations || true

      - name: Build docs/data for GitHub Pages
        run: |
          set -euo pipefail

          mkdir -p docs
          touch docs/.nojekyll

          rm -rf docs/data
          mkdir -p docs/data

          if [ -d site/data ]; then
            cp -v site/data/* docs/data/ || true
          fi

          cp -v data/gold/*.csv docs/data/ || true

          if [ -f site/data/stations_dim.csv ]; then
            cp -v site/data/stations_dim.csv docs/data/stations_dim.csv
          fi

          if [ -f site/data/capoluoghi_provincia.csv ]; then
            cp -v site/data/capoluoghi_provincia.csv docs/data/capoluoghi_provincia.csv
          fi

          if [ -f site/data/manifest.json ]; then
            cp -v site/data/manifest.json docs/data/manifest.json
          elif [ -f data/gold/manifest.json ]; then
            cp -v data/gold/manifest.json docs/data/manifest.json
          else
            python - <<'PY'
import os, json, glob, datetime
os.makedirs("docs/data", exist_ok=True)
gold = sorted([os.path.basename(p) for p in glob.glob("docs/data/*.csv")])
man = {
  "built_at_utc": datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z",
  "gold_files": gold,
}
with open("docs/data/manifest.json", "w", encoding="utf-8") as f:
  json.dump(man, f, ensure_ascii=False, indent=2)
print({"manifest_written": "docs/data/manifest.json", "gold_files": len(gold)})
PY
          fi

          echo "Docs data tree:"
          ls -la docs/data

      - name: Commit generated data and docs
        run: |
          set -euo pipefail

          git config user.name "github-actions"
          git config user.email "github-actions@users.noreply.github.com"

          git add data/ docs/ || true

          if git diff --cached --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Automated daily data update"
            git push
          fi
